{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/anaconda3/lib/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.2.2)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from bleach->kaggle) (23.2)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kaggle) (3.7)\n"
     ]
    }
   ],
   "source": [
    "# Installing the Kaggle Lib\n",
    "#!pip install kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Path for kaggle json file\n",
    "!mkdir -p ~/.kaggle/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp kaggle.json ~/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading playground-series-s4e8.zip to /Users/admin/Desktop/Machine-Learning/Data Collection and Preprocessing\n",
      "100%|█████████████████████████████████████▊| 82.0M/82.3M [00:13<00:00, 6.95MB/s]\n",
      "100%|██████████████████████████████████████| 82.3M/82.3M [00:13<00:00, 6.38MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c playground-series-s4e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted all files from the zip\n"
     ]
    }
   ],
   "source": [
    "# Let's know how to extract the data from the any Zip file \n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('/DataSets/playground-series-s4e8.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    print('Extracted all files from the zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion \n",
    "\n",
    "This how we Can extract the data and import the data through any api \n",
    "This is a simple way to extract data from Kaggle competitions, but for larger datasets or complex data preprocessing, you might need to use a more sophisticated approach, such as using pandas or Dask for data manipulation and preprocessing.\n",
    "Remember, always follow the dataset's terms of service and respect their privacy. \n",
    "\n",
    "For the data preprocessing part, it's a good idea to start with basic data cleaning, exploratory data analysis (EDA), and feature engineering. You can use libraries like pandas, matplotlib, seaborn, and scikit-learn for this purpose.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
